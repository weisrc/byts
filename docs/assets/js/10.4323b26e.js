(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{301:function(t,s,a){"use strict";a.r(s);var e=a(13),n=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"components"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#components"}},[t._v("#")]),t._v(" Components")]),t._v(" "),s("p",[t._v("The purpose of this section is to familiarize with the components and their relationships as well as their use cases. With this knowledge, you will be capable of fully extending Sir Dez to better fit your needs.")]),t._v(" "),s("h2",{attrs:{id:"serdes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#serdes"}},[t._v("#")]),t._v(" Serdes")]),t._v(" "),s("p",[t._v("Serdes are the building blocks used to create serializers and deserializers for complex data structures. However they are not very useful when used alone without a context. This is where "),s("code",[t._v("sd.UsableSerdes")]),t._v(" come into play.")]),t._v(" "),s("blockquote",[s("p",[t._v("Note: "),s("code",[t._v("sd")]),t._v(" comes from "),s("code",[t._v('import * as sd from "sirdez"')])])]),t._v(" "),s("h2",{attrs:{id:"usableserdes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#usableserdes"}},[t._v("#")]),t._v(" UsableSerdes")]),t._v(" "),s("p",[t._v("UsableSerdes are capable of serializing and deserializing data types and structures. A "),s("code",[t._v("sd.SerDes")]),t._v(" can be easily converted into it with "),s("code",[t._v("sd.use")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-ts extra-class"},[s("pre",{pre:!0,attrs:{class:"language-ts"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" bytes "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" same255 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromBytes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" bytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" same255 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("code",[t._v("toBytes")]),t._v(" encodes "),s("code",[t._v("255")]),t._v(" to a new "),s("code",[t._v("Uint8Array")]),t._v(", therefore it is safe to store. It is using "),s("code",[t._v("slice")]),t._v(" under the hood which creates a partial copy of the internal "),s("code",[t._v("Uint8Array")]),t._v(" found at "),s("code",[t._v("sd.Context#bytes")]),t._v(".")]),t._v(" "),s("p",[s("code",[t._v("fromBytes")]),t._v(" decodes the "),s("code",[t._v("encoded")]),t._v(" back to a JavaScript number.")]),t._v(" "),s("h3",{attrs:{id:"unsafe-serialization"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#unsafe-serialization"}},[t._v("#")]),t._v(" Unsafe serialization")]),t._v(" "),s("div",{staticClass:"language-ts extra-class"},[s("pre",{pre:!0,attrs:{class:"language-ts"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toUnsafeBytes "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("Creating a new "),s("code",[t._v("Uint8Array")]),t._v(" to return the encoded is not performant for larger data structures. To address this, converters have a second encoding method named "),s("code",[t._v("toUnsafeBytes")]),t._v(". "),s("strong",[s("code",[t._v("Uint8Array")]),t._v(" returned by "),s("code",[t._v("toUnsafeBytes")]),t._v(" must be used immediately and should not be stored because the data will be mutated on its next call.")]),t._v(" It is using "),s("code",[t._v("subarray")]),t._v(" under hood which does not return a copy.")]),t._v(" "),s("h2",{attrs:{id:"factories"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#factories"}},[t._v("#")]),t._v(" Factories")]),t._v(" "),s("p",[t._v("Sir Dez' Factories are the factories of "),s("code",[t._v("sd.Serdes")]),t._v(". Factories are the functions responsible for composing "),s("code",[t._v("sd.Serdes")]),t._v(" and creating new "),s("code",[t._v("sd.Serdes")]),t._v(" dynamically.")]),t._v(" "),s("div",{staticClass:"language-ts extra-class"},[s("pre",{pre:!0,attrs:{class:"language-ts"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" vector3dSerdes "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("struct")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  x"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  y"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  z"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vector3dSerdes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("code",[t._v("sd.struct")]),t._v(" is a "),s("code",[t._v("sd.StructFactory")]),t._v(". It creates "),s("code",[t._v("sd.Serdes")]),t._v(" given a key-value schema of "),s("code",[t._v("sd.Serdes")]),t._v(".")]),t._v(" "),s("h2",{attrs:{id:"encodings"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#encodings"}},[t._v("#")]),t._v(" Encodings")]),t._v(" "),s("p",[t._v("Encodings allow to encode string related data. Sir Dez comes with built-in encodings: "),s("code",[t._v("sd.utf8")]),t._v(", "),s("code",[t._v("sd.utf8js")]),t._v(", "),s("code",[t._v("sd.ucs2")]),t._v(", "),s("code",[t._v("sd.latin1")]),t._v(".")]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("sd.utf8")]),t._v(" uses the native "),s("code",[t._v("TextEncoder")]),t._v(" and "),s("code",[t._v("TextDecoder")]),t._v(". However, it somehow under performs for small strings, therefore "),s("code",[t._v("sd.utf8js")]),t._v(" is recommended for small strings.")])]),t._v(" "),s("div",{staticClass:"language-ts extra-class"},[s("pre",{pre:!0,attrs:{class:"language-ts"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utf8js"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("h2",{attrs:{id:"invalid-length-message-error-handling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#invalid-length-message-error-handling"}},[t._v("#")]),t._v(" Invalid Length Message Error Handling")]),t._v(" "),s("p",[t._v("The following statements summarizes how invalid length messages are handled:")]),t._v(" "),s("ul",[s("li",[t._v("Deserialize will throw RangeError for messages of invalid length")]),t._v(" "),s("li",[t._v("Deserialize will not process the extra bytes of a message that is too long")]),t._v(" "),s("li",[t._v("Deserialize internally successfully deserialize the message if it is too long, but will throw the error if the message is too long")])]),t._v(" "),s("p",[t._v("The error message it throws in case of an invalid length message are DataView out of bounds error and the following:")]),t._v(" "),s("div",{staticClass:"language-ts extra-class"},[s("pre",{pre:!0,attrs:{class:"language-ts"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("RangeError")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token template-string"}},[s("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("Expected to process ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("${")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" bytes, processed ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("${")]),t._v("ctx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(" bytes instead")]),s("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);