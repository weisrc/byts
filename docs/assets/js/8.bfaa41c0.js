(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{408:function(t,s,a){"use strict";a.r(s);var e=a(58),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"components"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#components"}},[t._v("#")]),t._v(" Components")]),t._v(" "),a("p",[t._v("The purpose of this section is to familiarize with the components and their relationships as well as their use cases. With this knowledge, you will be capable of fully extending Sir Dez to better fit your needs.")]),t._v(" "),a("h2",{attrs:{id:"serdes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#serdes"}},[t._v("#")]),t._v(" Serdes")]),t._v(" "),a("p",[t._v("Serdes are the building blocks used to create serializers and deserializers for complex data structures. However they are not very useful when used alone without a context. This is where "),a("code",[t._v("sd.UsableSerdes")]),t._v(" come into play.")]),t._v(" "),a("blockquote",[a("p",[t._v("Note: "),a("code",[t._v("sd")]),t._v(" comes from "),a("code",[t._v('import * as sd from "sirdez"')])])]),t._v(" "),a("h2",{attrs:{id:"usableserdes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#usableserdes"}},[t._v("#")]),t._v(" UsableSerdes")]),t._v(" "),a("p",[t._v("UsableSerdes are capable of serializing and deserializing data types and structures. A "),a("code",[t._v("sd.SerDes")]),t._v(" can be easily converted into it with "),a("code",[t._v("sd.use")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-ts extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ts"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" bytes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toBytes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" same255 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromBytes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bytes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" bytes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" same255 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("code",[t._v("toBytes")]),t._v(" encodes "),a("code",[t._v("255")]),t._v(" to a new "),a("code",[t._v("Uint8Array")]),t._v(", therefore it is safe to store. It is using "),a("code",[t._v("slice")]),t._v(" under the hood which creates a partial copy of the internal "),a("code",[t._v("Uint8Array")]),t._v(" found at "),a("code",[t._v("sd.Context#bytes")]),t._v(".")]),t._v(" "),a("p",[a("code",[t._v("fromBytes")]),t._v(" decodes the "),a("code",[t._v("encoded")]),t._v(" back to a JavaScript number.")]),t._v(" "),a("h3",{attrs:{id:"unsafe-serialization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#unsafe-serialization"}},[t._v("#")]),t._v(" Unsafe serialization")]),t._v(" "),a("div",{staticClass:"language-ts extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ts"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toUnsafeBytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("Creating a new "),a("code",[t._v("Uint8Array")]),t._v(" to return the encoded is not performant for larger data structures. To address this, converters have a second encoding method named "),a("code",[t._v("toUnsafeBytes")]),t._v(". "),a("strong",[a("code",[t._v("Uint8Array")]),t._v(" returned by "),a("code",[t._v("toUnsafeBytes")]),t._v(" must be used immediately and should not be stored because the data will be mutated on its next call.")]),t._v(" It is using "),a("code",[t._v("subarray")]),t._v(" under hood which does not return a copy.")]),t._v(" "),a("h2",{attrs:{id:"factories"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#factories"}},[t._v("#")]),t._v(" Factories")]),t._v(" "),a("p",[t._v("Sir Dez' Factories are the factories of "),a("code",[t._v("sd.Serdes")]),t._v(". Factories are the functions responsible for composing "),a("code",[t._v("sd.Serdes")]),t._v(" and creating new "),a("code",[t._v("sd.Serdes")]),t._v(" dynamically.")]),t._v(" "),a("div",{staticClass:"language-ts extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ts"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" vector3dSerdes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("struct")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  z"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float64\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vector3dSerdes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("code",[t._v("sd.struct")]),t._v(" is a "),a("code",[t._v("sd.StructFactory")]),t._v(". It creates "),a("code",[t._v("sd.Serdes")]),t._v(" given a key-value schema of "),a("code",[t._v("sd.Serdes")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"encodings"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#encodings"}},[t._v("#")]),t._v(" Encodings")]),t._v(" "),a("p",[t._v("Encodings allow to encode string related data. Sir Dez comes with built-in encodings: "),a("code",[t._v("sd.utf8")]),t._v(", "),a("code",[t._v("sd.utf8js")]),t._v(", "),a("code",[t._v("sd.utf16")]),t._v(", "),a("code",[t._v("sd.ascii")]),t._v(".")]),t._v(" "),a("blockquote",[a("p",[a("code",[t._v("sd.utf8")]),t._v(" uses the native "),a("code",[t._v("TextEncoder")]),t._v(" and "),a("code",[t._v("TextDecoder")]),t._v(". However, it somehow under performs for small strings, therefore "),a("code",[t._v("sd.utf8js")]),t._v(" is recommended for small strings.")])]),t._v(" "),a("div",{staticClass:"language-ts extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ts"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" toBytes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromBytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("use")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utf8js"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uint8"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);